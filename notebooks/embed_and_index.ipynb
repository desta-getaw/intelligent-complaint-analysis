{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833bf4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: matplotlib in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: sentence-transformers in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (5.0.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: tqdm in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: colorama in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\kifiya ai master training program 5 6 &7\\week-6\\intelligent-complaint-analysis\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.0 MB 1.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.0/15.0 MB 1.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.3/15.0 MB 1.6 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.6/15.0 MB 1.6 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.8/15.0 MB 1.5 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 2.1/15.0 MB 1.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 2.4/15.0 MB 1.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 2.6/15.0 MB 1.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.1/15.0 MB 1.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.4/15.0 MB 1.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 3.7/15.0 MB 1.5 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.9/15.0 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 4.2/15.0 MB 1.4 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 4.5/15.0 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.7/15.0 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.0/15.0 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.2/15.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 5.2/15.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 5.2/15.0 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 5.5/15.0 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.8/15.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.0/15.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.3/15.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.6/15.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.8/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.1/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.3/15.0 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.6/15.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.1/15.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.4/15.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.9/15.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.2/15.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.4/15.0 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.4/15.0 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.7/15.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.0/15.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.2/15.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.5/15.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.7/15.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.7/15.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.0/15.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 11.5/15.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.8/15.0 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.3/15.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 12.8/15.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.4/15.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.6/15.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 14.2/15.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/15.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib seaborn sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897996c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Project Root: d:\\Kifiya AI Master Training Program 5 6 &7\\week-6\\intelligent-complaint-analysis\n",
      "Attempting to load vector store from: d:\\Kifiya AI Master Training Program 5 6 &7\\week-6\\intelligent-complaint-analysis\\vector_store\\complaint_faiss_index\n",
      "\n",
      "Embedding model 'all-MiniLM-L6-v2' loaded successfully.\n",
      "\n",
      "Error: Vector store directory 'd:\\Kifiya AI Master Training Program 5 6 &7\\week-6\\intelligent-complaint-analysis\\vector_store\\complaint_faiss_index' not found.\n",
      "Please run 'src/embed_and_index.py' first to generate and persist the vector store.\n",
      "\n",
      "Skipping sample search as the vector store could not be loaded.\n",
      "\n",
      "--- Embed and Index Notebook Execution Complete ---\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# File: notebooks/embed_and_index.ipynb\n",
    "#text chunking, embedding, and indexing the Consumer Complaints dataset using FAISS\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document # Not strictly needed for loading, but good to have if showing document structure\n",
    "\n",
    "# --- 0. Set up Paths ---\n",
    "# We determine the project root dynamically based on the current working directory.\n",
    "# This assumes the notebook is launched either from the project root or the 'notebooks/' directory.\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "\n",
    "# Check if the current working directory ends with 'notebooks' (case-insensitive)\n",
    "if current_working_dir.lower().endswith(os.path.sep + 'notebooks'):\n",
    "    project_root = os.path.abspath(os.path.join(current_working_dir, os.pardir))\n",
    "else:\n",
    "    project_root = current_working_dir\n",
    "\n",
    "# Path to the persisted FAISS vector store\n",
    "vector_store_path = os.path.join(project_root, 'vector_store', 'complaint_faiss_index')\n",
    "\n",
    "print(f\"Detected Project Root: {project_root}\")\n",
    "print(f\"Attempting to load vector store from: {vector_store_path}\")\n",
    "\n",
    "# --- 1. Load the Embedding Model (must be the same as used for indexing) ---\n",
    "try:\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    print(f\"\\nEmbedding model '{embeddings.model_name}' loaded successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Error: 'sentence-transformers' library not found.\")\n",
    "    print(\"Please install it using: pip install sentence-transformers\")\n",
    "    embeddings = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embedding model: {e}\")\n",
    "    embeddings = None\n",
    "\n",
    "# --- 2. Load the Persisted FAISS Vector Store ---\n",
    "db = None\n",
    "if embeddings: # Only try to load if embedding model loaded successfully\n",
    "    if os.path.exists(vector_store_path):\n",
    "        try:\n",
    "            db = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            print(\"FAISS vector store loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading FAISS vector store from '{vector_store_path}': {e}\")\n",
    "            print(\"Ensure 'faiss-cpu' is installed and the index was saved correctly by 'src/embed_and_index.py'.\")\n",
    "    else:\n",
    "        print(f\"\\nError: Vector store directory '{vector_store_path}' not found.\")\n",
    "        print(\"Please run 'src/embed_and_index.py' first to generate and persist the vector store.\")\n",
    "else:\n",
    "    print(\"\\nSkipping vector store loading as embedding model could not be initialized.\")\n",
    "\n",
    "# --- 3. Perform a Sample Semantic Search (if DB loaded) ---\n",
    "if db:\n",
    "    print(\"\\n--- Performing a Sample Semantic Search ---\")\n",
    "    query = \"unauthorized transactions on my account\"\n",
    "    print(f\"Search Query: '{query}'\")\n",
    "\n",
    "    try:\n",
    "        # Perform similarity search\n",
    "        # k=3 retrieves the top 3 most relevant chunks\n",
    "        docs_with_scores = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "        print(\"\\nRetrieved Documents (Chunks):\")\n",
    "        for i, (doc, score) in enumerate(docs_with_scores):\n",
    "            print(f\"\\n--- Result {i+1} (Similarity Score: {score:.4f}) ---\")\n",
    "            print(f\"Complaint ID: {doc.metadata.get('complaint_id', 'N/A')}\")\n",
    "            print(f\"Product: {doc.metadata.get('product', 'N/A')}\")\n",
    "            print(f\"Chunk Content (first 200 chars): '{doc.page_content[:200]}...'\")\n",
    "            # print(f\"Full Chunk Content: '{doc.page_content}'\") # Uncomment to see full content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during similarity search: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping sample search as the vector store could not be loaded.\")\n",
    "\n",
    "print(\"\\n--- Embed and Index Notebook Execution Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
